{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pressing-hurricane",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    " 1. install and setup the classifcation model\n",
    " > https://github.com/cardiffnlp/tweeteval\n",
    " 2. clone the notebook repo\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-barrel",
   "metadata": {},
   "source": [
    "# Code #1: sentiment prediction tweets using open source trained model\n",
    "### (  + Autoscale naive approach  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-evans",
   "metadata": {
    "id": "J-FFwHN0jj3O"
   },
   "source": [
    "## Preliminaries\n",
    "\n",
    "We define a function to normalize a tweet to the format we used for TweetEval. Note that preprocessing is minimal (replacing user names by `@user` and links by `http`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collective-station",
   "metadata": {
    "id": "gKE0LowmYpTY"
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-germany",
   "metadata": {},
   "source": [
    "## Use TweetEval Classifiers\n",
    "\n",
    "We currently provide the following fine-tuned models for different tweet classification tasks:\n",
    "\n",
    "- emoji prediction (`emoji`)\n",
    "- emotion detection (`emotion`)\n",
    "- hate speech detection (`hate`)\n",
    "- irony detection (`irony`)\n",
    "- offensive language identification (`offensive`)\n",
    "- sentiment analysis (`sentiment`)\n",
    "- _(coming soon)_ stance detection (`stance`) with 5 targets (`abortion`, `atheism`, `climate`, `feminist`, `hillary`), for example: `stance-abortion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cultural-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-emotion\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# label mapping\n",
    "labels = ['anger', 'joy', 'optimism', 'sadness']\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "text = \"Bad night \"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "missing-understanding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) sadness 0.946\n",
      "2) anger 0.028\n",
      "3) joy 0.0186\n",
      "4) optimism 0.0074\n"
     ]
    }
   ],
   "source": [
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "italic-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use pandas\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "from typing import List\n",
    "import urllib.request\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-emotion\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# label mapping\n",
    "labels = ['anger', 'joy', 'optimism', 'sadness']\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nutritional-lawrence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01796203 0.8760045  0.04245262 0.06358095]\n"
     ]
    }
   ],
   "source": [
    "def sentimentPredict(text: str) -> [str]:\n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    return scores\n",
    "                                   \n",
    "res = sentimentPredict(\"hi my love\")\n",
    "\n",
    "print(res)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "desirable-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# banchmark lazy map\n",
    "import timeit\n",
    "num_runs = 10\n",
    "\n",
    "# read over eylon mask tweets csv\n",
    "elonTweets = pd.read_csv(\"./dataset/elonmusk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "promotional-charleston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "739 ms Â± 22.5 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "7.39 s Â± 260 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "1min 16s Â± 354 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "4min 17s Â± 36.5 s per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# python prediction \n",
    "%timeit elonTweets[\"tweet\"][0:10].map(sentimentPredict)\n",
    "%timeit elonTweets[\"tweet\"][0:100].map(sentimentPredict)\n",
    "%timeit elonTweets[\"tweet\"][0:1000].map(sentimentPredict)\n",
    "%timeit elonTweets[\"tweet\"][0:3000].map(sentimentPredict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-reasoning",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "# Code #2: Optimise using pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "collective-lounge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701 ms Â± 24.9 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "7.41 s Â± 143 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "1min 15s Â± 1.14 s per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "4min 1s Â± 13.1 s per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# panda prediction\n",
    "\n",
    "def sentimentPredictPd(s: pd.Series) -> pd.Series:\n",
    "    return s.map(sentimentPredict)\n",
    "   \n",
    "                                   \n",
    "%timeit sentimentPredictPd(elonTweets[\"tweet\"][0:10])\n",
    "%timeit sentimentPredictPd(elonTweets[\"tweet\"][0:100])\n",
    "%timeit sentimentPredictPd(elonTweets[\"tweet\"][0:1000])\n",
    "%timeit sentimentPredictPd(elonTweets[\"tweet\"][0:3000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-flight",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "# Code #3: Optimise using columnar memory format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fresh-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "from typing import List\n",
    "import urllib.request\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-emotion\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# label mapping\n",
    "labels = ['anger', 'joy', 'optimism', 'sadness']\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-briefing",
   "metadata": {},
   "source": [
    "### Without Arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "painted-museum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arrow.pyspark.enabled:  false\n",
      "arrow.enabled:  false\n",
      "Tweets count:  9379\n",
      "Partitsion count:  4\n",
      "+--------------------+--------------------+\n",
      "|               tweet|               score|\n",
      "+--------------------+--------------------+\n",
      "|!! Will take action.|[0.84155434, 0.01...|\n",
      "|           Nice ðŸ¤£ðŸ¤£|[0.024141183, 0.9...|\n",
      "|                  Ok|[0.3830172, 0.187...|\n",
      "|Customized horn &...|[0.29382166, 0.52...|\n",
      "|We need to do one...|[0.062386807, 0.5...|\n",
      "|\"Congrats to @Tal...|[0.0120146675, 0....|\n",
      "|Maybe end of next...|[0.079631224, 0.4...|\n",
      "|Whether Z-pak wor...|[0.054457296, 0.0...|\n",
      "|               False|[0.7806611, 0.032...|\n",
      "|We fought the Bal...|[0.26407075, 0.33...|\n",
      "|Rolling out a new...|[0.052287556, 0.7...|\n",
      "|Yes, about a mont...|[0.041002773, 0.7...|\n",
      "|@_Only_Hawk @MICH...|[0.08871256, 0.73...|\n",
      "|           Haha true|[0.016787158, 0.9...|\n",
      "|Yes, but still a ...|[0.08220884, 0.04...|\n",
      "|                Haha|[0.018273905, 0.9...|\n",
      "|Agreed, top prior...|[0.2593304, 0.031...|\n",
      "|Next landing atte...|[0.63255316, 0.02...|\n",
      "|                  ðŸ”¥|[0.20166908, 0.67...|\n",
      "|Autopilot prime d...|[0.084685594, 0.0...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 12.3 ms, sys: 9.17 ms, total: 21.5 ms\n",
      "Wall time: 2min 58s\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, ArrayType, FloatType, StructType, IntegerType, StructField\n",
    "\n",
    "#spark options\n",
    "\n",
    "NUMBER_OF_PARTITSION = 4\n",
    "MAX_RECORDS_PER_BATCH = 900\n",
    "\n",
    "spark = SparkSession.builder.appName(\"My-Application\").config(\"spark.driver.memory\", \"5g\").getOrCreate()\n",
    "\n",
    "elonmuskTweetsDf = spark.read.option(\"header\",True).csv(\"/Users/leeofri/Downloads/elonmusk.csv\")\n",
    "\n",
    "def sentimentPredict(text: str) -> [float]:\n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    return scores\n",
    "\n",
    "def predict_panda(itdf): \n",
    "    for df in itdf:\n",
    "        df[\"score\"] = df[\"tweet\"].map(lambda text: sentimentPredict(text))\n",
    "        yield df\n",
    "\n",
    "schema = StructType([\n",
    "        StructField(\"tweet\", StringType()),\n",
    "        StructField(\"score\", ArrayType(FloatType()))\n",
    "    ])\n",
    "\n",
    "elonmuskTweetsDf = elonmuskTweetsDf.repartition(4).filter(\"tweet != ''\")\n",
    "\n",
    "print(\"arrow.pyspark.enabled: \",spark.conf.get(\"spark.sql.execution.arrow.pyspark.enabled\"))\n",
    "print(\"arrow.enabled: \" ,spark.conf.get(\"spark.sql.execution.arrow.enabled\"))\n",
    "\n",
    "print(\"Tweets count: \" , elonmuskTweetsDf.count())\n",
    "print(\"Partitsion count: \" , elonmuskTweetsDf.rdd.getNumPartitions())\n",
    "\n",
    "resAll = elonmuskTweetsDf.mapInPandas(predict_panda,schema=schema)\n",
    "%time resAll.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-banner",
   "metadata": {},
   "source": [
    "### With Arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "later-confidence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arrow.pyspark.enabled:  true\n",
      "arrow.enabled:  true\n",
      "Tweets count:  9379\n",
      "Partitsion count:  4\n",
      "+--------------------+--------------------+\n",
      "|               tweet|               score|\n",
      "+--------------------+--------------------+\n",
      "|!! Will take action.|[0.84155434, 0.01...|\n",
      "|           Nice ðŸ¤£ðŸ¤£|[0.024141183, 0.9...|\n",
      "|                  Ok|[0.3830172, 0.187...|\n",
      "|Customized horn &...|[0.29382166, 0.52...|\n",
      "|We need to do one...|[0.062386807, 0.5...|\n",
      "|\"Congrats to @Tal...|[0.0120146675, 0....|\n",
      "|Maybe end of next...|[0.079631224, 0.4...|\n",
      "|Whether Z-pak wor...|[0.054457296, 0.0...|\n",
      "|               False|[0.7806611, 0.032...|\n",
      "|We fought the Bal...|[0.26407075, 0.33...|\n",
      "|Rolling out a new...|[0.052287556, 0.7...|\n",
      "|Yes, about a mont...|[0.041002773, 0.7...|\n",
      "|@_Only_Hawk @MICH...|[0.08871256, 0.73...|\n",
      "|           Haha true|[0.016787158, 0.9...|\n",
      "|Yes, but still a ...|[0.08220884, 0.04...|\n",
      "|                Haha|[0.018273905, 0.9...|\n",
      "|Agreed, top prior...|[0.2593304, 0.031...|\n",
      "|Next landing atte...|[0.63255316, 0.02...|\n",
      "|                  ðŸ”¥|[0.20166908, 0.67...|\n",
      "|Autopilot prime d...|[0.084685594, 0.0...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 9.26 ms, sys: 6.86 ms, total: 16.1 ms\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, ArrayType, FloatType, StructType, IntegerType, StructField\n",
    "\n",
    "#spark options\n",
    "\n",
    "NUMBER_OF_PARTITSION = 4\n",
    "MAX_RECORDS_PER_BATCH = 900\n",
    "\n",
    "# batch conf for pyarrow\n",
    "spark = SparkSession.builder.appName(\"My-Application2\").config(\"spark.driver.memory\", \"5g\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.fallback.enabled\", \"false\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", MAX_RECORDS_PER_BATCH) # max batch size!!\n",
    "\n",
    "elonmuskTweetsDf = spark.read.option(\"header\",True).csv(\"/Users/leeofri/Downloads/elonmusk.csv\")\n",
    "\n",
    "def sentimentPredict(text: str) -> [float]:\n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    return scores\n",
    "\n",
    "def predict_panda(itdf): \n",
    "    for df in itdf:\n",
    "        df[\"score\"] = df[\"tweet\"].map(lambda text: sentimentPredict(text))\n",
    "        yield df\n",
    "\n",
    "schema = StructType([\n",
    "        StructField(\"tweet\", StringType()),\n",
    "        StructField(\"score\", ArrayType(FloatType()))\n",
    "    ])\n",
    "\n",
    "elonmuskTweetsDf = elonmuskTweetsDf.repartition(4).filter(\"tweet != ''\")\n",
    "\n",
    "print(\"arrow.pyspark.enabled: \",spark.conf.get(\"spark.sql.execution.arrow.pyspark.enabled\"))\n",
    "print(\"arrow.enabled: \" ,spark.conf.get(\"spark.sql.execution.arrow.enabled\"))\n",
    "\n",
    "print(\"Tweets count: \" , elonmuskTweetsDf.count())\n",
    "print(\"Partitsion count: \" , elonmuskTweetsDf.rdd.getNumPartitions())\n",
    "\n",
    "resAll = elonmuskTweetsDf.mapInPandas(predict_panda,schema=schema)\n",
    "%time resAll.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-collapse",
   "metadata": {},
   "source": [
    "## Elon Mask emotions?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "combined-pendant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tweet: string (nullable = true)\n",
      " |-- score: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      " |-- anger: float (nullable = true)\n",
      " |-- joy: float (nullable = true)\n",
      " |-- optimism: float (nullable = true)\n",
      " |-- sadness: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentimentSpred = resAll.withColumn(\"anger\", resAll[\"score\"].getItem(0)).withColumn(\"joy\", resAll[\"score\"].getItem(1)).withColumn(\"optimism\",resAll[\"score\"].getItem(2)).withColumn(\"sadness\", resAll[\"score\"].getItem(3))\n",
    "\n",
    "sentimentSpred.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spoken-evidence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+-------------------+\n",
      "|           avg(joy)|      avg(optimism)|       avg(sadness)|         avg(anger)|\n",
      "+-------------------+-------------------+-------------------+-------------------+\n",
      "|0.37002909468911505|0.24679182631977264|0.16801638677369704|0.21516268802772973|\n",
      "+-------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentimentSpred.agg({\"anger\": \"avg\",\n",
    "                    \"joy\": \"avg\",\n",
    "                    \"optimism\": \"avg\",\n",
    "                    \"sadness\": \"avg\"}).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
